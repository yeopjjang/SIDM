{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72fda30b-5a37-4f5f-8fab-adbfcdd5cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "# columnar analysis\n",
    "from coffea import processor\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "import awkward as ak\n",
    "from dask.distributed import Client, performance_report\n",
    "# local\n",
    "\n",
    "sidm_path = str(os.getcwd()).split(\"/sidm\")[0]\n",
    "# sidm_path = str(sys.path[0]).split(\"/sidm\")[0]\n",
    "if sidm_path not in sys.path: sys.path.insert(1, sidm_path)\n",
    "from sidm.tools import utilities, sidm_processor, scaleout, cutflow\n",
    "from sidm.tools import llpnanoaodschema\n",
    "# always reload local modules to pick up changes during development\n",
    "importlib.reload(utilities)\n",
    "importlib.reload(sidm_processor)\n",
    "importlib.reload(scaleout)\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "utilities.set_plot_style()\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "import coffea.util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7537c4af-5e40-43ec-8839-06b413093c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-a3b44ec3-b4fc-11f0-80e6-3614af4a2f12</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Direct</td>\n",
       "            <td style=\"text-align: left;\"></td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/user/dongyub.lee@cern.ch/proxy/8787/status\" target=\"_blank\">/user/dongyub.lee@cern.ch/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/user/dongyub.lee@cern.ch/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Scheduler Info</h3></summary>\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-5cacbaaa-042c-487d-aa70-71560a97798a</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tls://192.168.121.97:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/user/dongyub.lee@cern.ch/proxy/8787/status\" target=\"_blank\">/user/dongyub.lee@cern.ch/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://192.168.121.97:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = scaleout.make_dask_client(\"tls://localhost:8786\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac6ef77-3a1f-4c82-9f2a-abc5202969bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    \"2Mu2E_200GeV_5p0GeV_0p2mm\",\n",
    "    \"2Mu2E_200GeV_5p0GeV_200p0mm\",\n",
    "    \"2Mu2E_1000GeV_0p25GeV_0p002mm\",\n",
    "    \"2Mu2E_1000GeV_0p25GeV_2p0mm\",\n",
    "    \"4Mu_200GeV_5p0GeV_0p2mm\",\n",
    "    \"4Mu_200GeV_5p0GeV_200p0mm\",\n",
    "    \"4Mu_1000GeV_0p25GeV_0p002mm\",\n",
    "    \"4Mu_1000GeV_0p25GeV_2p0mm\",\n",
    "    \"DYJetsToMuMu_M10to50\", \n",
    "    \"DYJetsToMuMu_M50\",    \n",
    "    \"TTJets\",\n",
    "    \"QCD_Pt120To170\",\n",
    "    \"QCD_Pt170To300\",\n",
    "    \"QCD_Pt300To470\",\n",
    "    \"QCD_Pt470To600\",\n",
    "    \"QCD_Pt600To800\",\n",
    "    \"QCD_Pt800To1000\",\n",
    "    \"QCD_Pt1000\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98bd1fe5-10b6-49b0-9278-6fb4cb2e07f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_bkg = [\n",
    "    \"DYJetsToMuMu_M10to50\", \n",
    "    \"DYJetsToMuMu_M50\",    \n",
    "    \"TTJets\",\n",
    "    \"QCD_Pt170To300\",\n",
    "    \"QCD_Pt300To470\",\n",
    "    \"QCD_Pt470To600\",\n",
    "    \"QCD_Pt600To800\",\n",
    "    \"QCD_Pt120To170\",\n",
    "    \"QCD_Pt800To1000\",\n",
    "    \"QCD_Pt1000\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b77b13c6-58dc-4409-9bd9-40afe8e5450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileset = utilities.make_fileset(samples[0:1], \n",
    "                                 \"llpNanoAOD_v2\", \n",
    "                                 location_cfg=\"signal_2mu2e_v10.yaml\",\n",
    "                                 max_files = 1,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "908fcd90-c5e1-4d30-b3ec-55a65dc7c6e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d77f3dcb9643a3ba50f2b9fd220bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2001baf1c2f4e6a8de0127a2afa43f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/site-packages/coffea/nanoevents/schemas/nanoaod.py:264: RuntimeWarning: Missing \n",
       "cross-reference index for LowPtElectron_electronIdx =&gt; Electron\n",
       "  warnings.warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.12/site-packages/coffea/nanoevents/schemas/nanoaod.py:264: RuntimeWarning: Missing \n",
       "cross-reference index for LowPtElectron_electronIdx => Electron\n",
       "  warnings.warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/site-packages/coffea/nanoevents/schemas/nanoaod.py:264: RuntimeWarning: Missing \n",
       "cross-reference index for LowPtElectron_photonIdx =&gt; Photon\n",
       "  warnings.warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.12/site-packages/coffea/nanoevents/schemas/nanoaod.py:264: RuntimeWarning: Missing \n",
       "cross-reference index for LowPtElectron_photonIdx => Photon\n",
       "  warnings.warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/site-packages/awkward/_nplikes/array_module.py:292: RuntimeWarning: invalid value \n",
       "encountered in divide\n",
       "  return impl(*broadcasted_args, **(kwargs or {}))\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.12/site-packages/awkward/_nplikes/array_module.py:292: RuntimeWarning: invalid value \n",
       "encountered in divide\n",
       "  return impl(*broadcasted_args, **(kwargs or {}))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Warning: Unable to apply all for nested dsaMuons collection. Skipping.... cannot slice ListArray (of length 1599) \n",
       "with [[1, 2], [1, 2], [1, 2, 3, 4], [], [2], [], ..., [0], [1, 2, 3], [], [], [2, 3]]: index out of range while \n",
       "attempting to get index 3 (in compiled code: \n",
       "https://github.com/scikit-hep/awkward/blob/awkward-cpp-45/awkward-cpp/src/cpu-kernels/awkward_ListArray_getitem_jag\n",
       "ged_apply.cpp#L43)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Warning: Unable to apply all for nested dsaMuons collection. Skipping.... cannot slice ListArray (of length 1599) \n",
       "with [[1, 2], [1, 2], [1, 2, 3, 4], [], [2], [], ..., [0], [1, 2, 3], [], [], [2, 3]]: index out of range while \n",
       "attempting to get index 3 (in compiled code: \n",
       "https://github.com/scikit-hep/awkward/blob/awkward-cpp-45/awkward-cpp/src/cpu-kernels/awkward_ListArray_getitem_jag\n",
       "ged_apply.cpp#L43)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--------------------------------------------------------------------------\n",
      "#                         FastJet release 3.4.3\n",
      "#                 M. Cacciari, G.P. Salam and G. Soyez                  \n",
      "#     A software package for jet finding and analysis at colliders      \n",
      "#                           http://fastjet.fr                           \n",
      "#\t                                                                      \n",
      "# Please cite EPJC72(2012)1896 [arXiv:1111.6097] if you use this package\n",
      "# for scientific work and optionally PLB641(2006)57 [hep-ph/0512210].   \n",
      "#                                                                       \n",
      "# FastJet is provided without warranty under the GNU GPL v2 or higher.  \n",
      "# It uses T. Chan's closest pair algorithm, S. Fortune's Voronoi code,\n",
      "# CGAL and 3rd party plugin jet algorithms. See COPYING file for details.\n",
      "#--------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.12/site-packages/awkward/_nplikes/array_module.py:292: RuntimeWarning: invalid value \n",
       "encountered in divide\n",
       "  return impl(*broadcasted_args, **(kwargs or {}))\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.12/site-packages/awkward/_nplikes/array_module.py:292: RuntimeWarning: invalid value \n",
       "encountered in divide\n",
       "  return impl(*broadcasted_args, **(kwargs or {}))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Warning: Unable to apply all for nested dsaMuons collection. Skipping.... cannot slice ListArray (of length 1599) \n",
       "with [[1, 2], [1, 2], [1, 2, 3, 4], [], [2], [], ..., [0], [1, 2, 3], [], [], [2, 3]]: index out of range while \n",
       "attempting to get index 3 (in compiled code: \n",
       "https://github.com/scikit-hep/awkward/blob/awkward-cpp-45/awkward-cpp/src/cpu-kernels/awkward_ListArray_getitem_jag\n",
       "ged_apply.cpp#L43)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Warning: Unable to apply all for nested dsaMuons collection. Skipping.... cannot slice ListArray (of length 1599) \n",
       "with [[1, 2], [1, 2], [1, 2, 3, 4], [], [2], [], ..., [0], [1, 2, 3], [], [], [2, 3]]: index out of range while \n",
       "attempting to get index 3 (in compiled code: \n",
       "https://github.com/scikit-hep/awkward/blob/awkward-cpp-45/awkward-cpp/src/cpu-kernels/awkward_ListArray_getitem_jag\n",
       "ged_apply.cpp#L43)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal not in xs cfg, assuming 1fb\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "list of filenames in fileset must be a list or a dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(samples):\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# print(f\"Processing {sample}\")\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     fileset_one_sample \u001b[38;5;241m=\u001b[39m {samples[i]:fileset\u001b[38;5;241m.\u001b[39mget(samples[i])}\n\u001b[0;32m---> 24\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset_one_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEvents\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#Add this sample's output to the out variable\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     out[sample] \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m][sample]\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/coffea/processor/executor.py:1573\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self, fileset, processor_instance, treename, uproot_options)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m fileset\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1573\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1576\u001b[0m     pi_to_send \u001b[38;5;241m=\u001b[39m processor_instance\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/coffea/processor/executor.py:1516\u001b[0m, in \u001b[0;36mRunner.preprocess\u001b[0;34m(self, fileset, treename)\u001b[0m\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected fileset to be a mapping dataset: list(files) or filename\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1514\u001b[0m     )\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1516\u001b[0m     fileset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_fileset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1517\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filemeta \u001b[38;5;129;01min\u001b[39;00m fileset:\n\u001b[1;32m   1518\u001b[0m         filemeta\u001b[38;5;241m.\u001b[39mmaybe_populate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_cache)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/coffea/processor/executor.py:1168\u001b[0m, in \u001b[0;36mRunner._normalize_fileset\u001b[0;34m(fileset, treename)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     local_treename \u001b[38;5;241m=\u001b[39m treename\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist of filenames in fileset must be a list or a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1170\u001b[0m     )\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_treename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename, local_treename \u001b[38;5;129;01min\u001b[39;00m filelist\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mValueError\u001b[0m: list of filenames in fileset must be a list or a dict"
     ]
    }
   ],
   "source": [
    "runner = processor.Runner(\n",
    "    # executor=processor.DaskExecutor(client=client),\n",
    "    executor=processor.IterativeExecutor(),\n",
    "    schema=llpnanoaodschema.LLPNanoAODSchema,\n",
    "    skipbadfiles=True\n",
    ")\n",
    "\n",
    "channels = [\n",
    "    \"base\", \"base_isosel\"\n",
    "]\n",
    "\n",
    "p = sidm_processor.SidmProcessor(\n",
    "    channels,\n",
    "    [\"matched_jet_base\", \"fraction_base\", \"isolation_base\", \"mother_tracking_base\", \"muon_crosscleaning_base\"],\n",
    "    unweighted_hist=False,\n",
    ")\n",
    "\n",
    "out = {}\n",
    "for i, sample in enumerate(samples):\n",
    "\n",
    "    # print(f\"Processing {sample}\")\n",
    "    fileset_one_sample = {samples[i]:fileset.get(samples[i])}\n",
    "    \n",
    "    output = runner.run(fileset_one_sample, treename='Events', processor_instance=p)\n",
    "\n",
    "    #Add this sample's output to the out variable\n",
    "    out[sample] = output[\"out\"][sample]\n",
    "\n",
    "    #Save output to a file!!\n",
    "    out_file_name = \"output_\" + sample + \".coffea\"\n",
    "    coffea.util.save(output,out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c1a034f-2eeb-40b4-8c1d-d3a70ef3cd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] sample=QCD_Pt1000, total_files=3087, batches=2\n",
      "  - Batch 1: 1544 files\n",
      "  - Batch 2: 1543 files\n",
      "[Batch 1/2] files: 1544 → running...\n",
      "[Batch 1] done → saved output_QCD_Pt1000_part1.coffea and dask-report_part1.html\n",
      "[Batch 2/2] files: 1543 → running...\n",
      "[Batch 2] done → saved output_QCD_Pt1000_part2.coffea and dask-report_part2.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from coffea.util import save, load\n",
    "from dask.distributed import performance_report\n",
    "try:\n",
    "    from coffea.processor import accumulate\n",
    "except Exception:\n",
    "    # 구버전 호환\n",
    "    from coffea.processor.accumulator import accumulate\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 0) 파라미터\n",
    "# ==============================\n",
    "SAMPLES_SLICE = samples_bkg[9:10]    # 질문에서와 동일\n",
    "TREE_NAME     = \"Events\"\n",
    "LOCATION_CFG  = \"background.yaml\"\n",
    "MAX_FILES     = -1\n",
    "N_BATCHES     = 2                   # 1500개 기준으로 자동 분할하려면 아래 AUTO_SPLIT 을 True로\n",
    "AUTO_SPLIT    = True                # True면 파일 수 기준(≈1500개)으로 배치 수 산정\n",
    "FILES_PER_BATCH_TARGET = 1600       # AUTO_SPLIT=True일 때 목표 파일 수\n",
    "\n",
    "# ======================================\n",
    "# 1) fileset 생성\n",
    "# ======================================\n",
    "fileset = utilities.make_fileset(\n",
    "    SAMPLES_SLICE,\n",
    "    \"skimmed_llpNanoAOD_v2\",\n",
    "    location_cfg=LOCATION_CFG,\n",
    "    max_files=MAX_FILES,\n",
    ")\n",
    "\n",
    "# 단일 샘플 가정\n",
    "assert len(fileset) == 1, \"이 스크립트는 단일 샘플 처리에 맞춰져 있습니다.\"\n",
    "sample_name = next(iter(fileset.keys()))\n",
    "sample_entry = fileset[sample_name]  # list / tuple / dict 가능\n",
    "\n",
    "# ======================================\n",
    "# 2) 파일 리스트 정규화 함수\n",
    "# ======================================\n",
    "def normalize_files(entry):\n",
    "    \"\"\"\n",
    "    fileset[sample]에서 '파일 경로 리스트'만 뽑아내고, 원래 entry 구조 유형을 반환.\n",
    "    반환: (file_list, entry_kind)\n",
    "      - entry_kind == \"list\"            : 원래가 리스트/튜플\n",
    "      - entry_kind == \"dict_files_key\"  : {\"files\": [...], ...} 형태\n",
    "      - entry_kind == \"dict_filemap\"    : {\"/path1.root\": meta, \"/path2.root\": meta, ...} 형태\n",
    "    \"\"\"\n",
    "    # case A: 이미 리스트/튜플\n",
    "    if isinstance(entry, (list, tuple)):\n",
    "        return list(entry), \"list\"\n",
    "\n",
    "    # case B: 딕셔너리\n",
    "    if isinstance(entry, dict):\n",
    "        # 표준 coffea 스타일: {\"files\": [...], ...}\n",
    "        if \"files\" in entry:\n",
    "            files = entry[\"files\"]\n",
    "            if isinstance(files, dict):   # 드물지만 \"files\"가 dict 인 경우\n",
    "                return list(files.keys()), \"dict_files_key\"\n",
    "            return list(files), \"dict_files_key\"\n",
    "        # 파일 경로를 key로 메타를 value로 들고 있는 형태\n",
    "        return list(entry.keys()), \"dict_filemap\"\n",
    "\n",
    "    raise TypeError(f\"Unsupported fileset entry type: {type(entry)}\")\n",
    "\n",
    "file_list, entry_kind = normalize_files(sample_entry)\n",
    "\n",
    "# ======================================\n",
    "# 3) 배치 분할 함수\n",
    "# ======================================\n",
    "def split_even(lst, n):\n",
    "    \"\"\"\n",
    "    lst를 n개의 (가능한 균등한) 조각으로 분할하여 리스트[chunks] 반환\n",
    "    \"\"\"\n",
    "    if n <= 0:\n",
    "        raise ValueError(\"n must be positive\")\n",
    "    k, m = divmod(len(lst), n)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    for i in range(n):\n",
    "        size = k + (1 if i < m else 0)\n",
    "        if size > 0:\n",
    "            chunks.append(lst[start:start+size])\n",
    "            start += size\n",
    "    return chunks\n",
    "\n",
    "# 배치 수 확정\n",
    "if AUTO_SPLIT:\n",
    "    N_BATCHES = max(1, math.ceil(len(file_list) / max(1, FILES_PER_BATCH_TARGET)))\n",
    "\n",
    "batches = split_even(file_list, N_BATCHES)\n",
    "\n",
    "print(f\"[Info] sample={sample_name}, total_files={len(file_list)}, batches={len(batches)}\")\n",
    "for i, b in enumerate(batches, 1):\n",
    "    print(f\"  - Batch {i}: {len(b)} files\")\n",
    "\n",
    "# ======================================\n",
    "# 4) 부분 실행 (이미 만들어진 파트는 스킵)\n",
    "# ======================================\n",
    "part_output_files = []\n",
    "\n",
    "for i, files_in_batch in enumerate(batches, start=1):\n",
    "    out_file_name = f\"output_{sample_name}_part{i}.coffea\"\n",
    "    report_name   = f\"dask-report_part{i}.html\"\n",
    "\n",
    "    # 이미 결과 파일이 있으면 스킵(재시도/재개)\n",
    "    if os.path.exists(out_file_name):\n",
    "        print(f\"[Batch {i}] 이미 {out_file_name} 존재 → 스킵합니다.\")\n",
    "        part_output_files.append(out_file_name)\n",
    "        continue\n",
    "\n",
    "    # 원래 entry 구조에 맞춰 부분 fileset 구성\n",
    "    if entry_kind == \"list\":\n",
    "        sub_fileset_entry = files_in_batch\n",
    "\n",
    "    elif entry_kind in (\"dict_files_key\", \"dict_filemap\"):\n",
    "        if isinstance(sample_entry, dict) and \"files\" in sample_entry:\n",
    "            # {\"files\":[...], ...} 형태 유지: 다른 메타는 그대로 복사\n",
    "            sub_fileset_entry = dict(sample_entry)  # 얕은 복사\n",
    "            sub_fileset_entry[\"files\"] = files_in_batch\n",
    "        else:\n",
    "            # {\"/path\": meta, ...} 형태였으면 부분 키만 선택\n",
    "            # (값이 필요 없는 변형이면 아래 dict comp가 빈 dict가 될 수 있어 안전장치 포함)\n",
    "            try:\n",
    "                sub_fileset_entry = {f: sample_entry[f] for f in files_in_batch}\n",
    "            except Exception:\n",
    "                # 키 접근이 안 되는 경우엔 단순 리스트로 전달\n",
    "                sub_fileset_entry = files_in_batch\n",
    "    else:\n",
    "        raise RuntimeError(\"Unexpected entry_kind\")\n",
    "\n",
    "    sub_fileset = {sample_name: sub_fileset_entry}\n",
    "\n",
    "    # Processor 인스턴스 준비(상태성 있을 수 있으니 가급적 새로 만들거나 deepcopy)\n",
    "    try:\n",
    "        p_to_use = deepcopy(p)\n",
    "    except Exception:\n",
    "        p_to_use = p\n",
    "\n",
    "    print(f\"[Batch {i}/{len(batches)}] files: {len(files_in_batch)} → running...\")\n",
    "\n",
    "    with performance_report(filename=report_name):\n",
    "        output = runner.run(\n",
    "            sub_fileset,\n",
    "            treename=TREE_NAME,\n",
    "            processor_instance=p_to_use,\n",
    "        )\n",
    "\n",
    "    save(output, out_file_name)\n",
    "    part_output_files.append(out_file_name)\n",
    "    print(f\"[Batch {i}] done → saved {out_file_name} and {report_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43282ec2-774e-4c1d-aa3a-07231a636c45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
