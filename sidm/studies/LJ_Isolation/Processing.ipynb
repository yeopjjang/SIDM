{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb404a03-f0e2-4bb4-9632-9a1ea33c4903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "# columnar analysis\n",
    "from coffea import processor\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "import awkward as ak\n",
    "from dask.distributed import Client, performance_report\n",
    "# local\n",
    "sidm_path = str(os.getcwd()).split(\"/sidm\")[0]\n",
    "# sidm_path = str(sys.path[0]).split(\"/sidm\")[0]\n",
    "if sidm_path not in sys.path: sys.path.insert(1, sidm_path)\n",
    "from sidm.tools import utilities, sidm_processor, scaleout, cutflow\n",
    "from sidm.tools import llpnanoaodschema\n",
    "# always reload local modules to pick up changes during development\n",
    "importlib.reload(utilities)\n",
    "importlib.reload(sidm_processor)\n",
    "importlib.reload(scaleout)\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "utilities.set_plot_style()\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "import coffea.util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8fdcd21-ce93-4cd5-ad85-d52f88c700b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-3362fdab-f5f5-11f0-8404-d669d8041e57</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Direct</td>\n",
       "            <td style=\"text-align: left;\"></td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/user/dongyub.lee@cern.ch/proxy/8787/status\" target=\"_blank\">/user/dongyub.lee@cern.ch/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/user/dongyub.lee@cern.ch/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Scheduler Info</h3></summary>\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-08219b46-8736-4af0-b0e8-f3ade0350b03</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tls://192.168.197.237:8786\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/user/dongyub.lee@cern.ch/proxy/8787/status\" target=\"_blank\">/user/dongyub.lee@cern.ch/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://192.168.197.237:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = scaleout.make_dask_client(\"tls://localhost:8786\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db737734-3aff-4cf7-aaaf-da791bd33156",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    # \"2Mu2E_100GeV_0p25GeV_0p2mm\",\n",
    "    # \"2Mu2E_100GeV_0p25GeV_10p0mm\",\n",
    "    # \"2Mu2E_100GeV_5p0GeV_4p0mm\",\n",
    "    # \"2Mu2E_100GeV_5p0GeV_200mm\",\n",
    "    # \"2Mu2E_150GeV_0p25GeV_0p13mm\",\n",
    "    # \"2Mu2E_150GeV_0p25GeV_6p7mm\",\n",
    "    # \"2Mu2E_150GeV_5p0GeV_2p7mm\",\n",
    "    # \"2Mu2E_150GeV_5p0GeV_130p0mm\",\n",
    "    # \"2Mu2E_200GeV_0p25GeV_0p1mm\",\n",
    "    # \"2Mu2E_200GeV_0p25GeV_5p0mm\",\n",
    "    # \"2Mu2E_200GeV_5p0GeV_2p0mm\",\n",
    "    # \"2Mu2E_200GeV_5p0GeV_100p0mm\",\n",
    "    # \"2Mu2E_500GeV_0p25GeV_0p04mm\",\n",
    "    # \"2Mu2E_500GeV_0p25GeV_2p0mm\",\n",
    "    \"2Mu2E_500GeV_5p0GeV_0p8mm\",\n",
    "    \"2Mu2E_500GeV_5p0GeV_40p0mm\",\n",
    "    \"2Mu2E_800GeV_0p25GeV_0p025mm\",\n",
    "    \"2Mu2E_800GeV_0p25GeV_1p2mm\",\n",
    "    \"2Mu2E_800GeV_5p0GeV_0p5mm\",\n",
    "    \"2Mu2E_800GeV_5p0GeV_25p0mm\",\n",
    "    \"2Mu2E_1000GeV_0p25GeV_0p02mm\",\n",
    "    \"2Mu2E_1000GeV_0p25GeV_1p0mm\",\n",
    "    \"2Mu2E_1000GeV_5p0GeV_0p4mm\",\n",
    "    \"2Mu2E_1000GeV_5p0GeV_20p0mm\",\n",
    "    \n",
    "    # \"DYJetsToMuMu_M10to50\", \n",
    "    # \"DYJetsToMuMu_M50\",    \n",
    "    # \"TTJets\",\n",
    "    # \"QCD_Pt80To120\",\n",
    "    # # \"QCD_Pt120To170\",\n",
    "    # \"QCD_Pt170To300\",\n",
    "    # \"QCD_Pt300To470\",\n",
    "    # \"QCD_Pt470To600\",\n",
    "    # \"QCD_Pt600To800\",\n",
    "    # # \"QCD_Pt800To1000\",\n",
    "    # \"QCD_Pt1000\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b857c49-ce93-44e9-8d43-3416585ad160",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_bkg = [ \n",
    "    \"TTJets\",\n",
    "    \"QCD_Pt80To120\", \n",
    "    # \"QCD_Pt120To170\",\n",
    "    \"QCD_Pt170To300\", \n",
    "    \"QCD_Pt300To470\",\n",
    "    \"QCD_Pt470To600\", \n",
    "    \"QCD_Pt600To800\", \n",
    "    # \"QCD_Pt800To1000\",\n",
    "    \"QCD_Pt1000\", \n",
    "    \"DYJetsToMuMu_M10to50\",\n",
    "    \"DYJetsToMuMu_M50\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21b56a15-bee3-42dd-85b9-9ffc773c87a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileset = utilities.make_fileset(samples[0:24], \n",
    "                                 \"llpNanoAOD_v2\", \n",
    "                                 location_cfg=\"signal_2mu2e_v10.yaml\",\n",
    "                                 max_files = -1,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48cb6efd-fa01-4328-b261-ff8fb829a103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2Mu2E_500GeV_5p0GeV_0p8mm is simulation. Scaling histograms or cutflows according to lumi*xs.\n",
      "Signal not in xs cfg, assuming 1fb\n",
      "2Mu2E_500GeV_5p0GeV_40p0mm is simulation. Scaling histograms or cutflows according to lumi*xs.\n",
      "Signal not in xs cfg, assuming 1fb\n",
      "2Mu2E_800GeV_0p25GeV_0p025mm is simulation. Scaling histograms or cutflows according to lumi*xs.\n",
      "Signal not in xs cfg, assuming 1fb\n",
      "2Mu2E_800GeV_0p25GeV_1p2mm is simulation. Scaling histograms or cutflows according to lumi*xs.\n",
      "Signal not in xs cfg, assuming 1fb\n",
      "2Mu2E_800GeV_5p0GeV_0p5mm is simulation. Scaling histograms or cutflows according to lumi*xs.\n",
      "Signal not in xs cfg, assuming 1fb\n",
      "2Mu2E_800GeV_5p0GeV_25p0mm is simulation. Scaling histograms or cutflows according to lumi*xs.\n",
      "Signal not in xs cfg, assuming 1fb\n",
      "2Mu2E_1000GeV_0p25GeV_0p02mm is simulation. Scaling histograms or cutflows according to lumi*xs.\n",
      "Signal not in xs cfg, assuming 1fb\n",
      "2Mu2E_1000GeV_0p25GeV_1p0mm is simulation. Scaling histograms or cutflows according to lumi*xs.\n",
      "Signal not in xs cfg, assuming 1fb\n",
      "2Mu2E_1000GeV_5p0GeV_0p4mm is simulation. Scaling histograms or cutflows according to lumi*xs.\n",
      "Signal not in xs cfg, assuming 1fb\n",
      "2Mu2E_1000GeV_5p0GeV_20p0mm is simulation. Scaling histograms or cutflows according to lumi*xs.\n",
      "Signal not in xs cfg, assuming 1fb\n"
     ]
    }
   ],
   "source": [
    "runner = processor.Runner(\n",
    "    executor=processor.DaskExecutor(client=client),\n",
    "    # executor=processor.IterativeExecutor(),\n",
    "    schema=llpnanoaodschema.LLPNanoAODSchema,\n",
    "    skipbadfiles=True\n",
    ")\n",
    "\n",
    "channels = [\n",
    "    # \"base_CC\", \"base_CC_isosel\"\n",
    "    \"base_CC_nocharge\", \"chargetest_basic\", \"chargetest_onlycharge\", \"chargetest_only2LJ\", \"munumtest_onlynum\", \"munumtest_both\", \"base_CC\"\n",
    "]\n",
    "\n",
    "p = sidm_processor.SidmProcessor(\n",
    "    channels,\n",
    "    # [\"matched_jet_base\", \"fraction_base\", \"isolation_base\", \"mother_tracking_base\", \"muon_crosscleaning_base\", \"exo_2d_base\"],\n",
    "    [\"charge_sum_base\", \"genA_base\", \"genA_toMu_base\", \"genA_toE_base\"],\n",
    "    unweighted_hist=False,\n",
    ")\n",
    "\n",
    "out = {}\n",
    "for i, sample in enumerate(samples):\n",
    "\n",
    "    # print(f\"Processing {sample}\")\n",
    "    fileset_one_sample = {samples[i]:fileset.get(samples[i])}\n",
    "    \n",
    "    output = runner.run(fileset_one_sample, treename='Events', processor_instance=p)\n",
    "\n",
    "    #Add this sample's output to the out variable\n",
    "    out[sample] = output[\"out\"][sample]\n",
    "\n",
    "    #Save output to a file!!\n",
    "    out_file_name = \"output_\" + sample + \".coffea\"\n",
    "    coffea.util.save(output,out_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5feec482-4f5f-4a4b-a73d-9c06a270167c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] sample=DYJetsToMuMu_M50, total_files=1000, batches=1\n",
      "  - Batch 1: 1000 files\n",
      "[Batch 1/1] files: 1000 → running...\n",
      "DYJetsToMuMu_M50 is simulation. Scaling histograms or cutflows according to lumi*xs.\n",
      "[Batch 1] done → saved output_DYJetsToMuMu_M50_part1.coffea and dask-report_part1.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from coffea.util import save, load\n",
    "from dask.distributed import performance_report\n",
    "try:\n",
    "    from coffea.processor import accumulate\n",
    "except Exception:\n",
    "    from coffea.processor.accumulator import accumulate\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 0) Parameter\n",
    "# ==============================\n",
    "SAMPLES_SLICE = samples_bkg[8:9]    \n",
    "TREE_NAME     = \"Events\"\n",
    "LOCATION_CFG  = \"backgrounds.yaml\"\n",
    "MAX_FILES     = 1000\n",
    "N_BATCHES     = 1                   \n",
    "AUTO_SPLIT    = False               \n",
    "FILES_PER_BATCH_TARGET = 7000       # Target files when AUTO_SPLIT=True\n",
    "\n",
    "# ======================================\n",
    "# 1) fileset\n",
    "# ======================================\n",
    "fileset = utilities.make_fileset(\n",
    "    SAMPLES_SLICE,\n",
    "    \"skimmed_llpNanoAOD_v2\",\n",
    "    location_cfg=LOCATION_CFG,\n",
    "    max_files=MAX_FILES,\n",
    ")\n",
    "\n",
    "# single sample\n",
    "assert len(fileset) == 1\n",
    "sample_name = next(iter(fileset.keys()))\n",
    "sample_entry = fileset[sample_name]  # list / tuple / dict\n",
    "\n",
    "# ======================================\n",
    "# 2) File list normalize function\n",
    "# ======================================\n",
    "def normalize_files(entry):\n",
    "    # case A: list/tuple\n",
    "    if isinstance(entry, (list, tuple)):\n",
    "        return list(entry), \"list\"\n",
    "\n",
    "    # case B: dict\n",
    "    if isinstance(entry, dict):\n",
    "        if \"files\" in entry:\n",
    "            files = entry[\"files\"]\n",
    "            if isinstance(files, dict):   \n",
    "                return list(files.keys()), \"dict_files_key\"\n",
    "            return list(files), \"dict_files_key\"\n",
    "        return list(entry.keys()), \"dict_filemap\"\n",
    "\n",
    "    raise TypeError(f\"Unsupported fileset entry type: {type(entry)}\")\n",
    "\n",
    "file_list, entry_kind = normalize_files(sample_entry)\n",
    "\n",
    "# ======================================\n",
    "# 3) Batch function\n",
    "# ======================================\n",
    "def split_even(lst, n):\n",
    "    if n <= 0:\n",
    "        raise ValueError(\"n must be positive\")\n",
    "    k, m = divmod(len(lst), n)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    for i in range(n):\n",
    "        size = k + (1 if i < m else 0)\n",
    "        if size > 0:\n",
    "            chunks.append(lst[start:start+size])\n",
    "            start += size\n",
    "    return chunks\n",
    "\n",
    "# Number of batch\n",
    "if AUTO_SPLIT:\n",
    "    N_BATCHES = max(1, math.ceil(len(file_list) / max(1, FILES_PER_BATCH_TARGET)))\n",
    "\n",
    "batches = split_even(file_list, N_BATCHES)\n",
    "\n",
    "print(f\"[Info] sample={sample_name}, total_files={len(file_list)}, batches={len(batches)}\")\n",
    "for i, b in enumerate(batches, 1):\n",
    "    print(f\"  - Batch {i}: {len(b)} files\")\n",
    "\n",
    "# ======================================\n",
    "# 4) Partial processing\n",
    "# ======================================\n",
    "part_output_files = []\n",
    "\n",
    "for i, files_in_batch in enumerate(batches, start=1):\n",
    "    out_file_name = f\"output_{sample_name}_part{i}.coffea\"\n",
    "    report_name   = f\"dask-report_part{i}.html\"\n",
    "\n",
    "    # Skip when file already exist\n",
    "    if os.path.exists(out_file_name):\n",
    "        print(f\"[Batch {i}] {out_file_name} already exist → Skipping.\")\n",
    "        part_output_files.append(out_file_name)\n",
    "        continue\n",
    "\n",
    "    if entry_kind == \"list\":\n",
    "        sub_fileset_entry = files_in_batch\n",
    "\n",
    "    elif entry_kind in (\"dict_files_key\", \"dict_filemap\"):\n",
    "        if isinstance(sample_entry, dict) and \"files\" in sample_entry:\n",
    "            sub_fileset_entry = dict(sample_entry) \n",
    "            sub_fileset_entry[\"files\"] = files_in_batch\n",
    "        else:\n",
    "            try:\n",
    "                sub_fileset_entry = {f: sample_entry[f] for f in files_in_batch}\n",
    "            except Exception:\n",
    "                sub_fileset_entry = files_in_batch\n",
    "    else:\n",
    "        raise RuntimeError(\"Unexpected entry_kind\")\n",
    "\n",
    "    sub_fileset = {sample_name: sub_fileset_entry}\n",
    "\n",
    "    # Processor\n",
    "    try:\n",
    "        p_to_use = deepcopy(p)\n",
    "    except Exception:\n",
    "        p_to_use = p\n",
    "\n",
    "    print(f\"[Batch {i}/{len(batches)}] files: {len(files_in_batch)} → running...\")\n",
    "\n",
    "    with performance_report(filename=report_name):\n",
    "        output = runner.run(\n",
    "            sub_fileset,\n",
    "            treename=TREE_NAME,\n",
    "            processor_instance=p_to_use,\n",
    "        )\n",
    "\n",
    "    save(output, out_file_name)\n",
    "    part_output_files.append(out_file_name)\n",
    "    print(f\"[Batch {i}] done → saved {out_file_name} and {report_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563502ab-5bd4-40ef-b2a3-cfb8faa7ef4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
